{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebook to extract features from the 3D shapes\n",
    "Written by Dominik Waibel & Niklas Kiermeyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import os \n",
    "import numpy as np\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import measure\n",
    "import trimesh\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import trimesh\n",
    "import cv2\n",
    "import math\n",
    "from skimage.transform import resize\n",
    "import numpy.linalg as linalg\n",
    "from pyellipsoid import drawing\n",
    "from skimage.feature import shape_index\n",
    "from scipy.ndimage.measurements import center_of_mass\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.filters import gaussian, threshold_otsu, gaussian_filter\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from skimage.morphology import convex_hull_image\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.measure import moments, inertia_tensor_eigvals\n",
    "from skimage.feature import hog\n",
    "from skimage.filters import gabor\n",
    "from skimage.morphology import convex_hull_image\n",
    "from scipy.ndimage.morphology import binary_dilation\n",
    "import mahotas\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to the 2D segmentations (\"mask\") and the folder where the features should be saved\n",
    "test_path = \"./ShapeAE_results/\"\n",
    "out_path = \"./Blood_cell/features/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize and threshold the data using Otsu's method: \n",
    "#https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_thresholding.html\n",
    "def norm_thres(data): \n",
    "    maxd = np.max(data)\n",
    "    data = data / maxd\n",
    "    data = np.nan_to_num(data)\n",
    "    if np.max(data) > 0:\n",
    "        thresh = threshold_otsu(data)\n",
    "        binary = data > thresh\n",
    "    else: \n",
    "        binary = data\n",
    "    return binary*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean curvature from a mesh\n",
    "def mean_curvature(verts, faces, obj):\n",
    "    mesh = trimesh.Trimesh(vertices = verts,faces=faces,process=False)\n",
    "    com = center_of_mass(obj)\n",
    "    z = int(round(np.nan_to_num(com[0])))\n",
    "    x = int(round(np.nan_to_num(com[1])))\n",
    "    y = int(round(np.nan_to_num(com[2])))\n",
    "    com = np.array(com)\n",
    "    com = np.array(com[np.newaxis,...])\n",
    "\n",
    "    (centers, radius) = trimesh.proximity.max_tangent_sphere(mesh, com, inwards=True, normals=None, threshold=1e-06, max_iter=100)\n",
    "    curve = trimesh.curvature.discrete_gaussian_curvature_measure(mesh, verts, radius)\n",
    "    return np.mean(curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the surface roughness from a mesh\n",
    "def roughness(verts, faces):\n",
    "    mesh = trimesh.Trimesh(vertices = verts,faces=faces,process=False)\n",
    "    smesh = trimesh.smoothing.filter_humphrey(mesh)\n",
    "    return np.mean(np.sqrt((np.sum((verts-smesh.vertices)**2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the surface roughness from voxels\n",
    "def roughtness2(obj): \n",
    "        smoothed = copy.deepcopy(gaussian_filter(obj,2))\n",
    "        smoothed = smoothed > 0.5\n",
    "        return np.sum(np.abs(smoothed-obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "files = os.listdir(test_path)\n",
    "print(len(files))\n",
    "\n",
    "gabor_header = [\"gabor\"+str(i) for i in range(64)]\n",
    "mesh_intertia_head = [\"mesh_intertia\"+str(i) for i in range(9)]\n",
    "mesh_principal0_head = [\"mesh_principal0\"+str(i) for i in range(3)]\n",
    "mesh_principal1_head = [\"mesh_principal1\"+str(i) for i in range(9)]\n",
    "\n",
    "with open(out_path + 'ShapeAE_features.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    #create and combine the header\n",
    "    header1 = ['filename', 'volume', 'surface', \"mean\", \n",
    "               'xy_bounary', 'xz_boundary', 'yz_boundary', \"boundary_3D\",\n",
    "               'shape_index', 'roughness', 'gauss_roughness', 'convexity',\n",
    "               \"zsum_mean\", \"zsum_std\",\"zsum_max\",\n",
    "              \"mean_faces\",\"median_faces\", \"std_faces\", \"mean_verts\",\"median_verts\", \"std_verts\",\n",
    "             \"moment_cr0_v\", \"moment_cc0_v\", \"moment_cr1_v\", \"moment_cc1_v\", \"moment_cr2_v\", \"moment_cc2_v\",\n",
    "              \"moment_cr_zsum\", \"moment_cc_zsum\",\n",
    "             \"glcm_diss\", \"glcm_corr\",\"inertia_eigvals0\", \"inertia_eigvals1\", \"inertia_eigvals2\",\n",
    "             \"num_faces\", \"num_verts\", \"gabor_zsum\", \n",
    "             \"mesh_volume\", \"mesh_convex_hull_volume\", \"xy_convexity\", \"xz_convexity\", \"yz_convexity\"]\n",
    "    header = header1 + gabor_header +mesh_intertia_head+ mesh_principal0_head + mesh_principal1_head\n",
    "    writer.writerow(header)\n",
    "    for index, file in enumerate(files): \n",
    "        print(index, file)\n",
    "        #read the data\n",
    "        data_in = np.squeeze(imread(test_path + file))\n",
    "        print(\"max\", np.max(data_in))\n",
    "        obj_auto_pred = np.nan_to_num(norm_thres(np.squeeze(data_in)))\n",
    "        #calcualte the convexity for each central slice \n",
    "        xy_convexity = np.sum(convex_hull_image(obj_auto_pred[32,:,:])-obj_auto_pred[32,:,:])\n",
    "        xz_convexity = np.sum(convex_hull_image(obj_auto_pred[:,32,:])-obj_auto_pred[:,32,:])\n",
    "        yz_convexity = np.sum(convex_hull_image(obj_auto_pred[:,:,32])-obj_auto_pred[:,:,32])\n",
    "        # calculate the boundary lenght for each central slice\n",
    "        k = np.ones((3,3),dtype=int)\n",
    "        obj = copy.deepcopy(obj_auto_pred)\n",
    "        k = np.ones((3,3),dtype=int)\n",
    "        obj = obj.astype(int)\n",
    "        xy_boundary = np.sum(binary_dilation(obj[32,:,:]==0, k) & obj[32,:,:])\n",
    "        yz_boundary = np.sum(binary_dilation(obj[:,:,32]==0, k) & obj[:,:,32])\n",
    "        xz_boundary = np.sum(binary_dilation(obj[:,32,:]==0, k) & obj[:,32,:])\n",
    "        #calculate the 3D boundary\n",
    "        boundary_3D = np.sum(binary_dilation(obj==0, np.ones((3,3,3),dtype=int)) & obj)\n",
    "        #calculate the pixel sum of the z-projection\n",
    "        obj_auto_pred_zsum = np.sum(obj_auto_pred, axis = 0)\n",
    "        #calculate features from the z-projection\n",
    "        zsum_mean = np.mean(obj_auto_pred_zsum)\n",
    "        zsum_std = np.std(obj_auto_pred_zsum)\n",
    "        zsum_max = np.max(obj_auto_pred_zsum)\n",
    "        #calculate glcm features\n",
    "        glcm = greycomatrix(obj_auto_pred_zsum.astype(\"uint8\"), distances=[5], angles=[0], levels=256,\n",
    "                    symmetric=True, normed=True)\n",
    "        glcm_diss = greycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "        glcm_corr = greycoprops(glcm, 'correlation')[0, 0]\n",
    "        #calculate the moments of the z-projection\n",
    "        m_zsum = measure.moments(obj_auto_pred_zsum)\n",
    "        cr_zsum = m_zsum[0, 1] / m_zsum[0, 0]\n",
    "        cc_zsum = m_zsum[1, 0] / m_zsum[0, 0]\n",
    "        #calculate the gabor features of the z-projection\n",
    "        gabor_zsum = np.sum(gabor(obj_auto_pred_zsum,1)[0])\n",
    "        #calculate the volume\n",
    "        auto_pred_vol = np.sum(obj_auto_pred)\n",
    "        #calculate the convexity\n",
    "        convexity = np.sum(convex_hull_image(obj_auto_pred)-obj_auto_pred)\n",
    "        #calculate the moments\n",
    "        m_v = measure.moments(obj_auto_pred)\n",
    "        cr0_v = m_v[0][0, 1] / m_v[0][0, 0]\n",
    "        cc0_v = m_v[0][1, 0] / m_v[0][0, 0]\n",
    "        cr1_v = m_v[1][0, 1] / m_v[1][0, 0]\n",
    "        cc1_v = m_v[1][1, 0] / m_v[1][0, 0]\n",
    "        cr2_v = m_v[2][0, 1] / m_v[2][0, 0]\n",
    "        cc2_v = m_v[2][1, 0] / m_v[2][0, 0]\n",
    "        #calculate the faces and vertices describing the 3D object\n",
    "        verts_pred, faces_pred, _, _ = measure.marching_cubes_lewiner(obj_auto_pred*255.)\n",
    "        #calculate the surface from the faces and vertices\n",
    "        surface_pred = measure.mesh_surface_area(verts_pred, faces_pred)\n",
    "        #calculate the gabor features\n",
    "        gabor_feat = []\n",
    "        for g in range(np.shape(obj_auto_pred)[0]): \n",
    "            gabor_feat.append(np.sum(gabor(obj_auto_pred[g,:,:],1)[0]))\n",
    "        #calculate the inertia eigenvalues\n",
    "        inertia_eigvals = inertia_tensor_eigvals(obj_auto_pred)\n",
    "        #calculate the mesh describing the 3D object from the faces and vertices\n",
    "        mesh = trimesh.Trimesh(vertices=verts_pred,\n",
    "                       faces=faces_pred,\n",
    "                       process=False)\n",
    "        #calculate the mesh interia and principal axes\n",
    "        mesh_intertia = list(mesh.moment_inertia.flatten())\n",
    "        mesh_principal = list(trimesh.inertia.principal_axis(mesh.moment_inertia))\n",
    "\n",
    "        tri_in = trimesh.inertia.principal_axis(mesh.moment_inertia)\n",
    "        mesh_principal0 = list(tri_in[0].flatten())\n",
    "        mesh_principal1 = list(tri_in[1].flatten())\n",
    "        #combine the features and write them to the .csv file\n",
    "        feat = [file, auto_pred_vol, surface_pred, np.mean(obj_auto_pred), \n",
    "                xy_boundary, xz_boundary, yz_boundary, boundary_3D,\n",
    "                mean_curvature(verts_pred, faces_pred,obj_auto_pred), \n",
    "                roughness(verts_pred, faces_pred), roughtness2(obj_auto_pred), convexity, \n",
    "                zsum_mean, zsum_std, zsum_max, \n",
    "                np.mean(faces_pred), np.median(faces_pred), np.std(faces_pred), np.mean(verts_pred),\n",
    "                np.median(verts_pred),\n",
    "                np.std(verts_pred),\n",
    "               cr0_v, cc0_v, cr1_v, cc1_v, cr2_v, cc2_v, cr_zsum, cc_zsum,\n",
    "               glcm_diss, glcm_corr, inertia_eigvals[0], inertia_eigvals[1], inertia_eigvals[2],\n",
    "               len(faces_pred), len(verts_pred), gabor_zsum, \n",
    "               mesh.volume, mesh.convex_hull.volume, xy_convexity, xz_convexity, yz_convexity] \n",
    "\n",
    "        feat = feat+ gabor_feat + mesh_intertia + mesh_principal0 + mesh_principal1\n",
    "        print(\"len features\", len(feat), len(header))\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
